{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Index Generation\n",
    "Generates indices for train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import h5py\n",
    "from collections import Counter\n",
    "from progressbar import *\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib\n",
    "#from watchmal.testing.repeating_classifier_training_utils import *\n",
    "from functools import reduce\n",
    "\n",
    "# Add the path to the parent directory to augment search for module\n",
    "par_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "if par_dir not in sys.path:\n",
    "    sys.path.append(par_dir)\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%matplotlib inline\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data_path = \"/fast_scratch/WatChMaL/data/IWCD_mPMT_Short_emg_E0to1000MeV_digihits.h5\"\n",
    "f = h5py.File(original_data_path, \"r\")\n",
    "\n",
    "labels = np.array(f['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['angles', 'energies', 'event_hits_index', 'event_ids', 'hit_charge', 'hit_pmt', 'hit_time', 'labels', 'positions', 'root_files', 'veto', 'veto2']>\n"
     ]
    }
   ],
   "source": [
    "# Import test events from h5 file\n",
    "original_data_path = \"/fast_scratch/WatChMaL/data/IWCD_mPMT_Short_emg_E0to1000MeV_digihits.h5\"\n",
    "f = h5py.File(original_data_path, \"r\")\n",
    "\n",
    "print(f.keys())\n",
    "\n",
    "hdf5_hit_pmt    = f[\"hit_pmt\"]\n",
    "hdf5_hit_time   = f[\"hit_time\"]\n",
    "hdf5_hit_charge = f[\"hit_charge\"]\n",
    "\n",
    "\n",
    "hit_pmt = np.memmap(original_data_path, mode=\"r\", shape=hdf5_hit_pmt.shape,\n",
    "                                    offset=hdf5_hit_pmt.id.get_offset(), dtype=hdf5_hit_pmt.dtype)\n",
    "\n",
    "hit_time = np.memmap(original_data_path, mode=\"r\", shape=hdf5_hit_time.shape,\n",
    "                                    offset=hdf5_hit_time.id.get_offset(), dtype=hdf5_hit_time.dtype)\n",
    "\n",
    "hit_charge = np.memmap(original_data_path, mode=\"r\", shape=hdf5_hit_charge.shape,\n",
    "                                    offset=hdf5_hit_charge.id.get_offset(), dtype=hdf5_hit_charge.dtype)\n",
    "\n",
    "angles     = np.array(f['angles'])\n",
    "energies   = np.array(f['energies'])\n",
    "positions  = np.array(f['positions'])\n",
    "labels     = np.array(f['labels'])\n",
    "root_files = np.array(f['root_files'])\n",
    "\n",
    "veto = np.array(f['veto'])\n",
    "veto2 = np.array(f['veto2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up indices\n",
    "indices = np.array(range(len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter indices based on vetos\n",
    "#overall_veto = np.logical_or(veto, veto2)\n",
    "overall_veto = veto\n",
    "\n",
    "filtered_indices    = indices[np.invert(overall_veto)]\n",
    "filtered_labels     = labels[np.invert(overall_veto)]\n",
    "filtered_root_files = root_files[np.invert(overall_veto)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(min(filtered_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{False, True}\n"
     ]
    }
   ],
   "source": [
    "print(set(overall_veto[0:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict set\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Set up dict of file indices\n",
    "file_dict = dict.fromkeys(root_files)\n",
    "print(\"Dict set\")\n",
    "\n",
    "for file in file_dict.keys():\n",
    "    file_dict[file] = []\n",
    "\n",
    "for idx, root_file in zip(filtered_indices, filtered_root_files):\n",
    "    file_dict[root_file].append(idx)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "1000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "# Get files associated with each particle type\n",
    "gamma_indices = filtered_indices[np.where(filtered_labels == 0)]\n",
    "gamma_root_file_set = list(dict.fromkeys(root_files[gamma_indices]))\n",
    "\n",
    "e_indices     = filtered_indices[np.where(filtered_labels == 1)]\n",
    "e_root_file_set = list(dict.fromkeys(root_files[e_indices]))\n",
    "\n",
    "mu_indices    = filtered_indices[np.where(filtered_labels == 2)]\n",
    "mu_root_file_set = list(dict.fromkeys(root_files[mu_indices]))\n",
    "\n",
    "print(len(e_root_file_set))\n",
    "print(len(mu_root_file_set))\n",
    "print(len(gamma_root_file_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define indices retrieval function\n",
    "def get_indices_for_files(file_names):\n",
    "    all_indices = []\n",
    "    for file_name in file_names:\n",
    "        all_indices.extend(file_dict[file_name])\n",
    "    return np.array(all_indices)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5900828 5900829 5900831 ... 7064959 7064962 7064965]\n"
     ]
    }
   ],
   "source": [
    "mu_test_files, mu_val_files, mu_train_files = mu_root_file_set[0:400], mu_root_file_set[400:500], mu_root_file_set[500:]\n",
    "\n",
    "mu_test_set, mu_val_set, mu_train_set = get_indices_for_files(mu_test_files), get_indices_for_files(mu_val_files), get_indices_for_files(mu_train_files)\n",
    "\n",
    "print(mu_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2944634 2944635 2944637 ... 4127008 4127009 4127010]\n"
     ]
    }
   ],
   "source": [
    "gamma_test_files, gamma_val_files, gamma_train_files = gamma_root_file_set[0:400], gamma_root_file_set[400:500], gamma_root_file_set[500:]\n",
    "\n",
    "gamma_test_set, gamma_val_set, gamma_train_set = get_indices_for_files(gamma_test_files), get_indices_for_files(gamma_val_files), get_indices_for_files(gamma_train_files)\n",
    "\n",
    "print(gamma_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      0       1       2 ... 1177963 1177964 1177965]\n"
     ]
    }
   ],
   "source": [
    "e_test_files, e_val_files, e_train_files = e_root_file_set[0:400], e_root_file_set[400:500], e_root_file_set[500:]\n",
    "\n",
    "e_test_set, e_val_set, e_train_set = get_indices_for_files(e_test_files), get_indices_for_files(e_val_files), get_indices_for_files(e_train_files)\n",
    "\n",
    "print(e_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'/localscratch/prouse.56905527.0/WCSim/e-/E0to1000MeV/unif-pos-R400-y300cm/4pi-dir/IWCD_mPMT_Short_e-_E0to1000MeV_unif-pos-R400-y300cm_4pi-dir_3000evts_0.root'\n",
      "b'/localscratch/prouse.56922977.0/WCSim/e-/E0to1000MeV/unif-pos-R400-y300cm/4pi-dir/IWCD_mPMT_Short_e-_E0to1000MeV_unif-pos-R400-y300cm_4pi-dir_3000evts_399.root'\n"
     ]
    }
   ],
   "source": [
    "print(e_test_files[0])\n",
    "print(e_test_files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "2500\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "print(len(mu_train_files))\n",
    "print(len(gamma_train_files))\n",
    "print(len(e_train_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1}\n",
      "{0}\n",
      "{2}\n"
     ]
    }
   ],
   "source": [
    "# Verify that indices match\n",
    "all_e_indices = np.concatenate((e_test_set, e_val_set, e_train_set))\n",
    "print(set(labels[all_e_indices]))\n",
    "\n",
    "all_gamma_indices = np.concatenate((gamma_test_set, gamma_val_set, gamma_train_set))\n",
    "print(set(labels[all_gamma_indices]))\n",
    "\n",
    "all_mu_indices = np.concatenate((mu_test_set, mu_val_set, mu_train_set))\n",
    "print(set(labels[all_mu_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20613195\n",
      "17415143\n",
      "17415143\n"
     ]
    }
   ],
   "source": [
    "# Verify that all events are uniquely accounted for\n",
    "all_collected_indices = np.concatenate((e_test_set, e_val_set, e_train_set, gamma_test_set, gamma_val_set, gamma_train_set, mu_test_set, mu_val_set, mu_train_set))\n",
    "\n",
    "print(len(labels))\n",
    "print(len(all_collected_indices))\n",
    "print(len(set(all_collected_indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs = np.concatenate((e_train_set, mu_train_set, gamma_train_set))\n",
    "val_idxs   = np.concatenate((e_val_set, mu_val_set, gamma_val_set))\n",
    "test_idxs  = np.concatenate((e_test_set, mu_test_set, gamma_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('./short_dataset_data/IWCD_mPMT_Short_3_class_emg_9M_OD_veto_idxs.npz', train_idxs=train_idxs, val_idxs=val_idxs, test_idxs=test_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Class e/gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs = np.concatenate((e_train_set, gamma_train_set))\n",
    "val_idxs   = np.concatenate((e_val_set, gamma_val_set))\n",
    "test_idxs  = np.concatenate((e_test_set, gamma_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('./short_dataset_data/IWCD_mPMT_Short_2_class_eg_9M_OD_veto_idxs.npz', train_idxs=train_idxs, val_idxs=val_idxs, test_idxs=test_idxs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
